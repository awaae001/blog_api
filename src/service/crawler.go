package service

import (
	"blog_api/src/model"
	"log"
	"net/http"
	"net/url"
	"time"

	"bytes"
	"io"

	"github.com/PuerkitoBio/goquery"
	"golang.org/x/net/html/charset"
)

// CrawlWebsite 获取并解析网站以提取 SEO 信息。
func CrawlWebsite(url string) model.CrawlResult {
	client := &http.Client{
		Timeout: 10 * time.Second, // 设置超时以防止挂起
		CheckRedirect: func(req *http.Request, via []*http.Request) error {
			return http.ErrUseLastResponse // 不跟随重定向
		},
	}

	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		log.Printf("[爬虫]创建获取 %s 的请求时出错: %v", url, err)
		return model.CrawlResult{Status: "error"}
	}
	req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 -  blog_api_webCrawler")
	resp, err := client.Do(req)
	if err != nil {
		log.Printf("[爬虫]获取 URL %s 时出错: %v", url, err)
		return model.CrawlResult{Status: "timeout"}
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 300 && resp.StatusCode < 400 {
		redirectURL := resp.Header.Get("Location")
		log.Printf("[crawler]检测到 %s 重定向到 %s", url, redirectURL)
		return model.CrawlResult{Status: "survival", RedirectURL: redirectURL}
	}

	if resp.StatusCode != http.StatusOK {
		log.Printf("[crawler]错误: %s 的状态码非 200: %d", url, resp.StatusCode)
		return model.CrawlResult{Status: "error"}
	}

	// 读取响应体内容
	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Printf("[crawler]读取 %s 的响应体时出错: %v", url, err)
		return model.CrawlResult{Status: "error"}
	}
	// 重置响应体以便后续读取
	resp.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	// 确定编码
	e, name, _ := charset.DetermineEncoding(bodyBytes, resp.Header.Get("Content-Type"))
	log.Printf("[crawler]确定 %s 的编码为: %s", url, name)

	// 使用检测到的编码创建读取器
	utf8Reader := e.NewDecoder().Reader(bytes.NewBuffer(bodyBytes))

	doc, err := goquery.NewDocumentFromReader(utf8Reader)
	if err != nil {
		log.Printf("[crawler]解析 %s 的 HTML 时出错: %v", url, err)
		return model.CrawlResult{Status: "error"}
	}

	// 查找描述
	description := doc.Find("meta[name='description']").AttrOr("content", "")

	// 查找网站图标
	iconURL, exists := doc.Find("link[rel='icon']").Attr("href")
	if !exists {
		// 兼容 apple-touch-icon 或 shortcut icon
		iconURL, exists = doc.Find("link[rel='apple-touch-icon']").Attr("href")
		if !exists {
			iconURL = doc.Find("link[rel='shortcut icon']").AttrOr("href", "")
		}
	}

	// 查找 RSS feeds
	var rssURLs []string
	doc.Find("link[rel='alternate']").Each(func(i int, s *goquery.Selection) {
		if href, exists := s.Attr("href"); exists {
			// 检查类型是否与 RSS 或 Atom 相关
			linkType, _ := s.Attr("type")
			if linkType == "application/rss+xml" || linkType == "application/atom+xml" {
				// 将相对 URL 解析为绝对 URL
				absoluteURL := toAbsoluteURL(resp.Request.URL, href)
				if absoluteURL != "" {
					rssURLs = append(rssURLs, absoluteURL)
				}
			}
		}
	})

	return model.CrawlResult{
		Description: description,
		IconURL:     iconURL,
		Status:      "survival",
		RssURLs:     rssURLs,
	}
}

// toAbsoluteURL 根据基础 URL 将相对 URL 转换为绝对 URL。
func toAbsoluteURL(base *url.URL, href string) string {
	relativeURL, err := url.Parse(href)
	if err != nil {
		return ""
	}
	return base.ResolveReference(relativeURL).String()
}
